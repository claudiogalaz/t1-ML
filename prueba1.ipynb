{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 - Manuel Figueroa y Claudio Galaz\n",
    "\n",
    "### 1. Regresión Lineal Ordinaria (LSS)\n",
    "\n",
    "Los datos son los siguientes:\n",
    ">**Prostate data info**\n",
    "\n",
    ">Predictors (columns 1--8)\n",
    "\n",
    ">outcome (column 9)\n",
    "\n",
    ">train/test indicator (column 10)\n",
    "\n",
    ">This last column indicates which 67 observations were used as the \n",
    "\"training set\" and which 30 as the test set.\n",
    "\n",
    ">The goal is to predict the log of PSA (prostate specific antigen) (**lpsa**) from a number of measurements including log cancer volume (**lcavol**), log prostate weight **lweight**, **age**, log of benign prostatic hyperplasia amount **lbph**, seminal vesicle invasion **svi**, log of capsular penetration **lcp**, Gleason score gleason, and percent of Gleason scores 4 or 5 **pgg45**. \n",
    "\n",
    "#### a)\n",
    "Primero se importan las librerías y los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep ='\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se elimina la primera columna de los datos, que contiene el número de fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y después se crean arreglos con los datos de training/test set, y se elimina esa columna de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "\n",
    "df = df.drop('train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente quedan dos arreglos booleanos: **istrain** que es *True* para los datos que forman parte del training set e **istest** que es la operación lógica *NOT* sobre el primer set, marcando con *True* los elementos del test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Las lineas de a continuación muestran información relevante sobre los datos extraídos. Estos son la cantidad de datos (count), el promedio (mean), desviación estándar (std), dato máximo (max), dato mínimo (min), y los percentiles 25, 50 y 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97 entries, 0 to 96\n",
      "Data columns (total 9 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 7.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from IPython.display import clear_output\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los datos se puede observar que la característica *svi* es binaria, *gleason* es entera con valores entre 6 y 9, y *pgg45* es una variable porcentual y entera.\n",
    "\n",
    "#### c)\n",
    "\n",
    "Antes de entrar a trabajar con los datos es importante **normalizarlos**. Esto es necesario puesto que, como cada dimension tiene su propia escala de datos, se hace difícil comparar entre dimensiones. \n",
    "\n",
    "Por ejemplo, *age* varía entre 41 y 79 y *lweight* se mueve entre 2.374906 y 4.780383, por lo que para poder trabajar con estos datos en conjunto es importante llevarlos a una misma escala.\n",
    "\n",
    "Una vez normalizada, la columna de la característica *lpsa* debe quedar como estaba antes (sin normalizar) debido a que es el objetivo a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.614302e-17</td>\n",
       "      <td>-3.216213e-16</td>\n",
       "      <td>3.433679e-16</td>\n",
       "      <td>-4.721309e-17</td>\n",
       "      <td>-1.327689e-16</td>\n",
       "      <td>8.240831e-17</td>\n",
       "      <td>-1.476482e-16</td>\n",
       "      <td>-1.816989e-16</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.300218e+00</td>\n",
       "      <td>-2.942386e+00</td>\n",
       "      <td>-3.087227e+00</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.139973e-01</td>\n",
       "      <td>-5.937689e-01</td>\n",
       "      <td>-5.219612e-01</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.264956e-02</td>\n",
       "      <td>-1.392703e-02</td>\n",
       "      <td>1.531086e-01</td>\n",
       "      <td>1.383966e-01</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-4.450983e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>-3.343557e-01</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.626939e-01</td>\n",
       "      <td>5.806076e-01</td>\n",
       "      <td>5.581506e-01</td>\n",
       "      <td>1.010033e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>9.762744e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>5.566470e-01</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.107397e+00</td>\n",
       "      <td>2.701661e+00</td>\n",
       "      <td>2.043304e+00</td>\n",
       "      <td>1.542252e+00</td>\n",
       "      <td>1.902379e+00</td>\n",
       "      <td>2.216735e+00</td>\n",
       "      <td>3.128363e+00</td>\n",
       "      <td>2.695054e+00</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lcavol       lweight           age          lbph           svi  \\\n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01   \n",
       "mean  -9.614302e-17 -3.216213e-16  3.433679e-16 -4.721309e-17 -1.327689e-16   \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00   \n",
       "min   -2.300218e+00 -2.942386e+00 -3.087227e+00 -1.030029e+00 -5.256575e-01   \n",
       "25%   -7.139973e-01 -5.937689e-01 -5.219612e-01 -1.030029e+00 -5.256575e-01   \n",
       "50%    8.264956e-02 -1.392703e-02  1.531086e-01  1.383966e-01 -5.256575e-01   \n",
       "75%    6.626939e-01  5.806076e-01  5.581506e-01  1.010033e+00 -5.256575e-01   \n",
       "max    2.107397e+00  2.701661e+00  2.043304e+00  1.542252e+00  1.902379e+00   \n",
       "\n",
       "                lcp       gleason         pgg45       lpsa  \n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  97.000000  \n",
       "mean   8.240831e-17 -1.476482e-16 -1.816989e-16   2.478387  \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00   1.154329  \n",
       "min   -8.676552e-01 -1.047571e+00 -8.689573e-01  -0.430783  \n",
       "25%   -8.676552e-01 -1.047571e+00 -8.689573e-01   1.731656  \n",
       "50%   -4.450983e-01  3.444069e-01 -3.343557e-01   2.591516  \n",
       "75%    9.762744e-01  3.444069e-01  5.566470e-01   3.056357  \n",
       "max    2.216735e+00  3.128363e+00  2.695054e+00   5.582932  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['lpsa'] = df['lpsa']\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los promedios de todos los datos normalizados son muy pequeños comparado con los datos, por lo que se puede decir que el promedio es prácticamente cero.\n",
    "\n",
    "#### d)\n",
    "\n",
    "A continuación se realiza una regresión lineal de mínimos cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.ix[:,:-1]\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['lpsa']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[istest]\n",
    "ytest = y[istest]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tercer paso (cuarta línea) agrega una columna llena de números 1, llamada **intercept**, a la derecha de la última columna (*lpsa*). Esta columna representa el valor de $x_0 $ en la matriz de los predictores de tal forma que el intercepto sea $\\beta_0$.\n",
    "\n",
    "Como los datos están normalizados, estos tienen sus promedios centrados y no es necesario calcular el intercepto (es cero)\n",
    "\n",
    "#### e)\n",
    "\n",
    "Se calculan los z scores como $$z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j}}$$ \n",
    "\n",
    "Donde $v_j$ es el elemento j-esimo de la diagonal de la matriz $(X^T X)^{-1}$ y el la desviación $\\sigma$ es estimada como: $$\\hat{\\sigma}^2 = \\frac{1}{N-p-1} \\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fcf7a8887ebc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmat_vj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mvj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_vj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numpy\\core\\fromnumeric.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transpose() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "betas = linreg.coef_\n",
    "\n",
    "N = Xtrain.shape[0]\n",
    "p = Xtrain.shape[1]\n",
    "sigma = sum((linreg.predict(Xtrain) - ytrain) ** 2)/ (N - p -1)\n",
    "\n",
    "mat_vj = np.dot(np.transpose(Xtrain),Xtrain)\n",
    "vj = np.diag(np.linalg.inv(mat_vj))\n",
    "\n",
    "z_score = betas/np.sqrt(sigma*vj)\n",
    "\n",
    "print ('{0:12} {1:15} {2:12}'.format(\"Variable\", \"Coeficiente\", \"Z Score\"))\n",
    "print \"-------------------------------------\"\n",
    "for i in range(z_score.shape[0]):\n",
    "    print ('{0:10} {1:10.3f} {2:12.3f}'.format(Xtrain.columns.values[i],betas[i],z_score[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El Z-score permite identificar aquellas variables que no deberían tener un $\\beta = 0$. Un Z-score mayor a 1.96 (valor absoluto) tiene una significancia del 5%. En este caso se observa claramente que **lcavol** es la variable más relacionada con el resultado ya que tanto su coeficiente como el Z-score son los mayores. \n",
    "\n",
    "Las varialbes **lweight**, **lbph** y **svi** quedan también sobre el 5% de significancia, se puede decir que el resto de las variables (**age, lcp, gleason y pgg45**) no hay evidencia de que estén relacionadas con el resultado.\n",
    "\n",
    "#### f)\n",
    "\n",
    "En el siguiente código se calcula el error cuadrático medio en el modelo utilizado hasta ahora, y luego se crea el modelo utilizando cross-validation con k-folds utilizando 5 y 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n",
    "\n",
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "from sklearn import cross_validation\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "\n",
    "print \"Error en test set antes de Cross-validation: %.3f \"%(mse_test)\n",
    "\n",
    "for i in range(2):\n",
    "    k_fold = cross_validation.KFold(len(Xm),(5*i+5))\n",
    "    mse_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        linreg = lm.LinearRegression(fit_intercept = False)\n",
    "        linreg.fit(Xm[train], ym[train])\n",
    "        yhat_val = linreg.predict(Xm[val])\n",
    "        mse_fold = np.mean(np.power(yhat_val - ym[val],2))\n",
    "        mse_cv += mse_fold\n",
    "    mse_v = mse_cv/(5*i+5)\n",
    "    print \"Error promedio con %d\"%(5*i+5), \"folds: %3f \" %(mse_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error del modelo al utilizar cross validation aumenta, esto quiere decir que los resultados del modelo anterior están sobre ajustados a los datos de entrenamiento.\n",
    "\n",
    "#### g)\n",
    "\n",
    "Finalmente se realiza un gráfico quantile-quantile para analizar si los errores de predicción del modelo siguen una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n",
    "y_predicted = linreg.predict(Xtrain)\n",
    "\n",
    "measurements = (y_predicted - ytrain)\n",
    "\n",
    "stats.probplot(measurements, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se observa a simple vista que los puntos se encuentran sobre la linea de la distribución normal, y el R$^2$ del modelo es de 0.9806 por lo que se puede aceptar la hiótesis de normalidad de los residuos de los datos de entrenamiento\n",
    "\n",
    "### 2. Selección de atributos\n",
    "\n",
    "\n",
    "Se crearon algoritmos de forward selection y backwards selection. El primero se modificó para tomar como criterio de selección de atributos el error cuadrático medio de los datos de test, además se agregaron los errores de test set y train set de cada modelo al retorno del algoritmo.\n",
    "\n",
    "El algoritmo de backwards selection se basa en el primero pero en éste el modelo inicial contiene todas las variables y se van eliminando de a una, eligiendo siempre la que mantenga el menor mse con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fss(x, y, x2, y2, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    test_errors = []\n",
    "    train_errors = []\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            x_test = x2[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            predictions_test= model.predict(x_test)\n",
    "            residuals_test = predictions_test - y2\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            mse_test = np.mean(np.power(residuals_test, 2))\n",
    "            score_candidates.append((mse_test, mse_candidate, candidate)) #criterio de seleccion es error en test set\n",
    "        score_candidates.sort()\n",
    "        #print score_candidates\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_train_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        test_errors.append(best_new_score)\n",
    "        train_errors.append(best_train_score)\n",
    "        #print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        #print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    return selected, train_errors, test_errors\n",
    "\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "\n",
    "\n",
    "Xm2 = Xtest.as_matrix()\n",
    "ym2 = ytest.as_matrix()\n",
    "fss_selected, fss_train_error, fss_test_error = fss(Xm,ym,Xm2,ym2,names_regressors)\n",
    "\n",
    "def bss(x, y, x2, y2, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    modelo_anterior = range(0,p+1)\n",
    "    selected = [p]\n",
    "    test_errors = []\n",
    "    train_errors = []\n",
    "    \n",
    "    #modelo completo\n",
    "    model = lm.LinearRegression(fit_intercept=False)\n",
    "    predictions_train = model.fit(x, y).predict(x)\n",
    "    residuals_train = predictions_train - y\n",
    "    predictions_test= model.predict(x2)\n",
    "    residuals_test = predictions_test - y2\n",
    "    mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "    mse_test = np.mean(np.power(residuals_test, 2))\n",
    "    test_errors.append(mse_test)\n",
    "    train_errors.append(mse_candidate)\n",
    "    \n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while len(remaining)>1 and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:            \n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = modelo_anterior[:]\n",
    "            indexes.remove(candidate)\n",
    "            x_train = x[:,indexes]\n",
    "            x_test = x2[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            predictions_test= model.predict(x_test)\n",
    "            residuals_test = predictions_test - y2\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            mse_test = np.mean(np.power(residuals_test, 2))\n",
    "            score_candidates.append((mse_test, mse_candidate, candidate)) #criterio de seleccion es error en test set\n",
    "        score_candidates.sort()\n",
    "        #print score_candidates\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_train_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        modelo_anterior.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        test_errors.append(best_new_score)\n",
    "        train_errors.append(best_train_score)\n",
    "        #print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        #print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    #agrego el que quedo en la lista que sería el último en sacar\n",
    "    selected.append(remaining[0])\n",
    "    return selected, train_errors, test_errors\n",
    "\n",
    "bss_selected, bss_train_error, bss_test_error = bss(Xm,ym,Xm2,ym2,names_regressors)\n",
    "\n",
    "#saco el 8 de la lista porque es el intercepto\n",
    "bss_selected.remove(8)\n",
    "fss_selected.remove(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eje_x = range(1,9)\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(eje_x, fss_train_error, 'ro-', label='FSS train mse')\n",
    "plt.plot(eje_x, fss_test_error, 'go-', label = 'FSS test mse')\n",
    "plt.legend(loc=4)\n",
    "plt.xlim(0,9)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "eje_x = range(8,0,-1)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(eje_x, bss_train_error, 'ro-', label='BSS train mse')\n",
    "plt.plot(eje_x, bss_test_error, 'go-', label = 'BSS test mse')\n",
    "plt.legend(loc=4)\n",
    "plt.xlim(0,9)\n",
    "plt.ylim(0,1)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print 'fss order of selection:', fss_selected\n",
    "print 'bss order of deletion:', bss_selected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación de gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regularización\n",
    "**a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X = X.drop('intercept', axis = 1) #Elimina la columna de intercepto\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "alphas_ = np.logspace(4,-1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept = True, solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    print alphas_.shape\n",
    "    print y_arr.shape\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
