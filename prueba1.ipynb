{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 - Manuel Figueroa y Claudio Galaz\n",
    "\n",
    "### 1 Regresión Lineal Ordinaria (LSS)\n",
    "\n",
    "Los datos son los siguientes:\n",
    ">**Prostate data info**\n",
    "\n",
    ">Predictors (columns 1--8)\n",
    "\n",
    ">outcome (column 9)\n",
    "\n",
    ">train/test indicator (column 10)\n",
    "\n",
    ">This last column indicates which 67 observations were used as the \n",
    "\"training set\" and which 30 as the test set.\n",
    "\n",
    ">The goal is to predict the log of PSA (prostate specific antigen) (**lpsa**) from a number of measurements including log cancer volume (**lcavol**), log prostate weight **lweight**, **age**, log of benign prostatic hyperplasia amount **lbph**, seminal vesicle invasion **svi**, log of capsular penetration **lcp**, Gleason score gleason, and percent of Gleason scores 4 or 5 **pgg45**. \n",
    "\n",
    "#### a)\n",
    "Primero se importan las librerías y los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep ='\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se elimina la primera columna de los datos, que contiene el número de fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y después se crean arreglos con los datos de training/test set, y se elimina esa columna de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "\n",
    "df = df.drop('train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente quedan dos arreglos booleanos: **istrain** que es *True* para los datos que forman parte del training set e **istest** que es la operación lógica *NOT* sobre el primer set, marcando con *True* los elementos del test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Las lineas de a continuación muestran información relevante sobre los datos extraídos. Estos son la cantidad de datos (count), el promedio (mean), desviación estándar (std), dato máximo (max), dato mínimo (min), y los percentiles 25, 50 y 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 9 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 6.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from IPython.display import clear_output\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los datos se puede observar que la característica *svi* es binaria, *gleason* es entera con valores entre 6 y 9, y *pgg45* es una variable porcentual y entera.\n",
    "\n",
    "#### c)\n",
    "\n",
    "Antes de entrar a trabajar con los datos es importante **normalizarlos**. Esto es necesario puesto que, como cada dimension tiene su propia escala de datos, se hace difícil comparar entre dimensiones. \n",
    "\n",
    "Por ejemplo, *age* varía entre 41 y 79 y *lweight* se mueve entre 2.374906 y 4.780383, por lo que para poder trabajar con estos datos en conjunto es importante llevarlos a una misma escala.\n",
    "\n",
    "Una vez normalizada, la columna de la característica *lpsa* debe quedar como estaba antes (sin normalizar) debido a que es el objetivo a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.204767e-17</td>\n",
       "      <td>-3.170431e-16</td>\n",
       "      <td>4.131861e-16</td>\n",
       "      <td>-2.432190e-17</td>\n",
       "      <td>-3.662591e-17</td>\n",
       "      <td>3.662591e-17</td>\n",
       "      <td>-2.174664e-17</td>\n",
       "      <td>5.636957e-17</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.300218e+00</td>\n",
       "      <td>-2.942386e+00</td>\n",
       "      <td>-3.087227e+00</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.139973e-01</td>\n",
       "      <td>-5.937689e-01</td>\n",
       "      <td>-5.219612e-01</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.264956e-02</td>\n",
       "      <td>-1.392703e-02</td>\n",
       "      <td>1.531086e-01</td>\n",
       "      <td>1.383966e-01</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-4.450983e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>-3.343557e-01</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.626939e-01</td>\n",
       "      <td>5.806076e-01</td>\n",
       "      <td>5.581506e-01</td>\n",
       "      <td>1.010033e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>9.762744e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>5.566470e-01</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.107397e+00</td>\n",
       "      <td>2.701661e+00</td>\n",
       "      <td>2.043304e+00</td>\n",
       "      <td>1.542252e+00</td>\n",
       "      <td>1.902379e+00</td>\n",
       "      <td>2.216735e+00</td>\n",
       "      <td>3.128363e+00</td>\n",
       "      <td>2.695054e+00</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lcavol       lweight           age          lbph           svi  \\\n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01   \n",
       "mean   3.204767e-17 -3.170431e-16  4.131861e-16 -2.432190e-17 -3.662591e-17   \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00   \n",
       "min   -2.300218e+00 -2.942386e+00 -3.087227e+00 -1.030029e+00 -5.256575e-01   \n",
       "25%   -7.139973e-01 -5.937689e-01 -5.219612e-01 -1.030029e+00 -5.256575e-01   \n",
       "50%    8.264956e-02 -1.392703e-02  1.531086e-01  1.383966e-01 -5.256575e-01   \n",
       "75%    6.626939e-01  5.806076e-01  5.581506e-01  1.010033e+00 -5.256575e-01   \n",
       "max    2.107397e+00  2.701661e+00  2.043304e+00  1.542252e+00  1.902379e+00   \n",
       "\n",
       "                lcp       gleason         pgg45       lpsa  \n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  97.000000  \n",
       "mean   3.662591e-17 -2.174664e-17  5.636957e-17   2.478387  \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00   1.154329  \n",
       "min   -8.676552e-01 -1.047571e+00 -8.689573e-01  -0.430783  \n",
       "25%   -8.676552e-01 -1.047571e+00 -8.689573e-01   1.731656  \n",
       "50%   -4.450983e-01  3.444069e-01 -3.343557e-01   2.591516  \n",
       "75%    9.762744e-01  3.444069e-01  5.566470e-01   3.056357  \n",
       "max    2.216735e+00  3.128363e+00  2.695054e+00   5.582932  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['lpsa'] = df['lpsa']\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los promedios de todos los datos normalizados son muy pequeños comparado con los datos, por lo que se puede decir que el promedio es prácticamente cero.\n",
    "\n",
    "#### d)\n",
    "\n",
    "A continuación se realiza una regresión lineal de mínimos cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.ix[:,:-1]\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['lpsa']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[istest]\n",
    "ytest = y[istest]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tercer paso (cuarta línea) agrega una columna llena de números 1, llamada **intercept**, a la derecha de la última columna (*lpsa*). Esta columna representa el valor de $x_0 $ en la matriz de los predictores de tal forma que el intercepto sea $\\beta_0$.\n",
    "\n",
    "Como los datos están normalizados, estos tienen sus promedios centrados y no es necesario calcular el intercepto (es cero)\n",
    "\n",
    "#### e)\n",
    "\n",
    "Se calculan los z scores como $$z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j}}$$ \n",
    "\n",
    "Donde $v_j$ es el elemento j-esimo de la diagonal de la matriz $(X^T X)^{-1}$ y el la desviación $\\sigma$ es estimada como: $$\\hat{\\sigma}^2 = \\frac{1}{N-p-1} \\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43701406945\n",
      "Variable     Coeficiente     Z Score     \n",
      "-------------------------------------\n",
      "lcavol          0.676        5.320\n",
      "lweight         0.262        2.727\n",
      "age            -0.141       -1.384\n",
      "lbph            0.209        2.038\n",
      "svi             0.304        2.448\n",
      "lcp            -0.287       -1.851\n",
      "gleason        -0.021       -0.145\n",
      "pgg45           0.266        1.723\n",
      "intercept       2.465       27.359\n"
     ]
    }
   ],
   "source": [
    "betas = linreg.coef_\n",
    "\n",
    "N = Xtrain.shape[0]\n",
    "p = Xtrain.shape[1]\n",
    "sigma = sum((linreg.predict(Xtrain) - ytrain) ** 2)/ (N - p -1)\n",
    "\n",
    "mat_vj = np.dot(np.transpose(Xtrain),Xtrain)\n",
    "vj = np.diag(np.linalg.inv(mat_vj))\n",
    "\n",
    "z_score = betas/np.sqrt(sigma*vj)\n",
    "\n",
    "print ('{0:12} {1:15} {2:12}'.format(\"Variable\", \"Coeficiente\", \"Z Score\"))\n",
    "print \"-------------------------------------\"\n",
    "for i in range(z_score.shape[0]):\n",
    "    print ('{0:10} {1:10.3f} {2:12.3f}'.format(Xtrain.columns.values[i],betas[i],z_score[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El Z-score permite identificar aquellas variables que no deberían tener un $\\beta = 0$. Un Z-score mayor a 1.96 (valor absoluto) tiene una significancia del 5%. En este caso se observa claramente que **lcavol** es la variable más relacionada con el resultado ya que tanto su coeficiente como el Z-score son los mayores. \n",
    "\n",
    "Las varialbes **lweight**, **lbph** y **svi** quedan también sobre el 5% de significancia, se puede decir que el resto de las variables (**age, lcp, gleason y pgg45**) no hay evidencia de que estén relacionadas con el resultado.\n",
    "\n",
    "#### f)\n",
    "\n",
    "En el siguiente código se calcula el error cuadrático medio en el modelo utilizado hasta ahora, y luego se crea el modelo utilizando cross-validation con k-folds utilizando 5 y 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en test set antes de Cross-validation: 0.521 \n",
      "Error promedio con 5 folds: 0.956515 \n",
      "Error promedio con 10 folds: 0.757237 \n"
     ]
    }
   ],
   "source": [
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n",
    "\n",
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "from sklearn import cross_validation\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "\n",
    "print \"Error en test set antes de Cross-validation: %.3f \"%(mse_test)\n",
    "\n",
    "for i in range(2):\n",
    "    k_fold = cross_validation.KFold(len(Xm),(5*i+5))\n",
    "    mse_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        linreg = lm.LinearRegression(fit_intercept = False)\n",
    "        linreg.fit(Xm[train], ym[train])\n",
    "        yhat_val = linreg.predict(Xm[val])\n",
    "        mse_fold = np.mean(np.power(yhat_val - ym[val],2))\n",
    "        mse_cv += mse_fold\n",
    "    mse_v = mse_cv/(5*i+5)\n",
    "    print \"Error promedio con %d\"%(5*i+5), \"folds: %3f \" %(mse_v)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error del modelo al utilizar cross validation aumenta, esto quiere decir que los resultados del modelo anterior están sobre ajustados a los datos de entrenamiento.\n",
    "\n",
    "#### g)\n",
    "\n",
    "Finalmente se realiza un gráfico quantile-quantile para analizar si los errores de predicción del modelo siguen una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEZCAYAAABmTgnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngP4f4jasymeCTV0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6887d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n",
    "y_predicted = linreg.predict(Xtrain)\n",
    "\n",
    "measurements = (y_predicted - ytrain)\n",
    "\n",
    "stats.probplot(measurements, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se observa a simple vista que los puntos se encuentran sobre la linea de la distribución normal, y el R$^2$ del modelo es de 0.9806 por lo que se puede aceptar la hiótesis de normalidad de los residuos de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected = Lcavol ...\n",
      "totalvars=2, mse = 0.664606\n",
      "selected = Lweight ...\n",
      "totalvars=3, mse = 0.553610\n",
      "selected = Svi ...\n",
      "totalvars=4, mse = 0.521011\n",
      "selected = Lbph ...\n",
      "totalvars=5, mse = 0.489776\n",
      "selected = Pgg45 ...\n",
      "totalvars=6, mse = 0.478648\n",
      "selected = Lcp ...\n",
      "totalvars=7, mse = 0.455818\n",
      "selected = Age ...\n",
      "totalvars=8, mse = 0.439363\n",
      "selected = Gleason ...\n",
      "totalvars=9, mse = 0.439200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 0, 1, 4, 3, 7, 5, 2, 6]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    return selected\n",
    "\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "\n",
    "fss(Xm,ym,names_regressors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
